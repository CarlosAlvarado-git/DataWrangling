{
 "cells": [
  {
   "cell_type": "raw",
   "id": "b3aec1af",
   "metadata": {},
   "source": [
    "# Laboratorio #8 - Missing Data and Feature Engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52571da5",
   "metadata": {},
   "source": [
    "# 1.\tReporte detallado de missing data para todas las columnas. "
   ]
  },
  {
   "cell_type": "raw",
   "id": "cd64b26e",
   "metadata": {},
   "source": [
    "Las columanas: Sex, Age, SibSp, Parch, Fare, Embarked. Cuentan con missing data"
   ]
  },
  {
   "cell_type": "raw",
   "id": "b9eed1d5",
   "metadata": {},
   "source": [
    "En este caso Sex, tiene valores de: male, female y ?. Por lo que se toma el ? como missing data.\n",
    "En la columana de Age, hay con espacios vacios que son considerados como missing data.\n",
    "    La columna maneja datos de tipo integer y doubles.\n",
    "La columna de Fare son los precios de los tickets. Maneja datos de tipo doubles.\n",
    "La columna Parch, presenta un tipo de missing data donde literalemente contiene NA, pero de tipo String y no de NaN que maneja python. \n",
    "    Cuenta con 0,1,2,4 como valores\n",
    "Para Fare, hay missing data por espacios en blanco. \n",
    "    Fare cuenta con valores de tipo double\n",
    "En la columna embarked, hay espacios vaciós, por lo tanto son contados como missing data. \n",
    "    Cuenta con S y C como los únicos valores. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80938027",
   "metadata": {},
   "source": [
    "# 2.\tPara cada columna especificar qué tipo de modelo se utilizará (solo el nombre y el porqué) y qué valores se le darán a todos los missing values. (Ej. Imputación sectorizada por la moda, bins, y cualquier otro método visto anteriormente). "
   ]
  },
  {
   "cell_type": "raw",
   "id": "a7936005",
   "metadata": {},
   "source": [
    "Sex: para esta colúmna se haría una imputación sectorizada, debido a que esta nos va a permitir acercarnos un poco más a los deatos reales. Los factores como edad, la fare, y el embarked posiblemente nos pueden decir si es hombre o mujer, pero eso se vería más haciendo una pairwise para saber cuales tienen más correlación con el sexo y utilizarlo en la imputación. \n",
    "Age: En este caso se haría una regresión lineal, para poder predecirlo de mejor manera. Los valores que irían para módelo con la edad, la clase y (SibSP o Parch) ya que relaciona la edad con la cantidad de familiares que van en el barco también, otra opción puede ser la edad y el Fare sólamente, o la edad y clase.\n",
    "SibSp: Los sibSp podría utilizar una imputación de fill, es decir, que el valor anterior sea asignado al que está vacio, ya que en este caso, la data no cuenta con muchos missing values seguidos en la columna, por lo que no sesgaría la data. \n",
    "Parch: de igual manera, utilizaría fill, ya que no cuenta con muchos missing values seguidos de la columna y por lo tanto no sesgaría la data. \n",
    "Fare: En este caso utilizaría outliters donde pondría un rango entre el 10% y 95%, y haría un cap, así traería los valores hacia mi 10% o el 95% aquellos que se pasan o no llegan, ya que considero que por las clases, los precios prodrían estar en ese margen y que por lo tanto, permitirían un análisis un poco más certero. \n",
    "Embarked: Por sen tan pocos los missing values, utilizaría el método de fill, ya que la separación de esos missing values en la columna es lo suficiente para que no sesge la data. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65156e9f",
   "metadata": {},
   "source": [
    "# 3.\tReporte de qué filas están completas "
   ]
  },
  {
   "cell_type": "raw",
   "id": "a8d9e68f",
   "metadata": {},
   "source": [
    "Passanger ID: columna completa con el ID del pasagero, son de tipo integer. \n",
    "Survived: columan con valores de 0 y 1, que determinan si el pasagero murio (0) o sobrevivio (1).\n",
    "Pclass: columna que muestra en que clase viajaba el pasajero, en este caso cuenta de 1 hasta 3 clase. \n",
    "Name: los nombres de los pasajeros si está registrado por completo. \n",
    "Ticket: los tickes muestran el boleto que compro la persona, por lo que me intriga aquellos datos que cuenta con valores que parecen ser varios tickets. \n",
    "Cabin: la cabina en la que el pasajero estuvo o en la que fue asignado probablemente durante el viaje. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fbb30ec",
   "metadata": {},
   "source": [
    "# 4.\tUtilizar los siguientes métodos para cada columna que contiene missing values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3c1b091",
   "metadata": {},
   "source": [
    "1. Limpieza de los Missing Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "0ff8334a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "523154a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('titanic_MD.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "118266ea",
   "metadata": {},
   "source": [
    "Cambiar los vacios, los ? por NaN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "595687b2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cols</th>\n",
       "      <th>val</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Name</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Sex</td>\n",
       "      <td>51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Ticket</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Cabin</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Embarked</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       cols  val\n",
       "0      Name    0\n",
       "1       Sex   51\n",
       "2    Ticket    0\n",
       "3     Cabin    0\n",
       "4  Embarked    0"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    " # Cambiar los ? por NaN\n",
    "cols = []\n",
    "val = []\n",
    "for col in data.select_dtypes(include='object').columns:\n",
    "    cols.append(col)\n",
    "    val.append(data[col].str.contains(r'\\?').sum())\n",
    "pd.DataFrame({\n",
    "    'cols':cols,\n",
    "    'val':val\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "f672ceb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.replace(r'\\?', np.nan, regex = True, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "f148c904",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PassengerId     0\n",
       "Survived        0\n",
       "Pclass          0\n",
       "Name            0\n",
       "Sex            51\n",
       "Age            25\n",
       "SibSp           3\n",
       "Parch          12\n",
       "Ticket          0\n",
       "Fare            8\n",
       "Cabin           0\n",
       "Embarked       12\n",
       "dtype: int64"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "a2e96f93",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aproximar la edad para dejarlo en enteros\n",
    "data['Age'] = round(data['Age'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "02cfc168",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tener todo en dos decimales\n",
    "data['Fare'] = round(data['Fare'], 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "16e219f9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>pct</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>PassengerId</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Survived</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Pclass</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Name</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Sex</td>\n",
       "      <td>0.278689</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Age</td>\n",
       "      <td>0.136612</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>SibSp</td>\n",
       "      <td>0.016393</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Parch</td>\n",
       "      <td>0.065574</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Ticket</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Fare</td>\n",
       "      <td>0.043716</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Cabin</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Embarked</td>\n",
       "      <td>0.065574</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          index       pct\n",
       "0   PassengerId  0.000000\n",
       "1      Survived  0.000000\n",
       "2        Pclass  0.000000\n",
       "3          Name  0.000000\n",
       "4           Sex  0.278689\n",
       "5           Age  0.136612\n",
       "6         SibSp  0.016393\n",
       "7         Parch  0.065574\n",
       "8        Ticket  0.000000\n",
       "9          Fare  0.043716\n",
       "10        Cabin  0.000000\n",
       "11     Embarked  0.065574"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Ver el % de missing values en las columnas. \n",
    "pct = pd.DataFrame(data.isna().sum()/data.shape[0], columns = ['pct']).reset_index()\n",
    "pct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27aa30cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sólo el sex y la age sobrepasan el 10%, pero considero que no es necesario eliminarlas. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bb096ee",
   "metadata": {},
   "source": [
    "Imputaciones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "49bc60c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.impute import SimpleImputer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "da68f10a",
   "metadata": {},
   "outputs": [],
   "source": [
    "imp_mean = SimpleImputer(missing_values=np.nan, strategy='mean')\n",
    "imp_median = SimpleImputer(missing_values=np.nan, strategy='median')\n",
    "imp_mode = SimpleImputer(missing_values=np.nan, strategy='most_frequent')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb2c2d24",
   "metadata": {},
   "source": [
    "Sex:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "a739a5b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_imputaciones = pd.DataFrame(imp_mode.fit_transform(data[['Sex']]), columns = ['Sex_mode'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "256523c2",
   "metadata": {},
   "source": [
    "Age:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "d4ea8822",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_imputaciones['Age_mean'] = imp_mean.fit_transform(data[['Age']])\n",
    "data_imputaciones['Age_mean'] = round(data_imputaciones['Age_mean'], 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "ecc8b2f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_imputaciones['Age_mode'] = imp_mode.fit_transform(data[['Age']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "ae8d92b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_imputaciones['Age_median'] = imp_median.fit_transform(data[['Age']])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90be745d",
   "metadata": {},
   "source": [
    "SibSp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "2e6a8b2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_imputaciones['SibSp_mean'] = imp_mean.fit_transform(data[['SibSp']])\n",
    "data_imputaciones['SibSp_mean'] = round(data_imputaciones['SibSp_mean'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "82947ad3",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_imputaciones['SibSp_mode'] = imp_mode.fit_transform(data[['SibSp']])\n",
    "data_imputaciones['SibSp_mode'] = round(data_imputaciones['SibSp_mode'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "92cddbb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_imputaciones['SibSp_median'] = imp_median.fit_transform(data[['SibSp']])\n",
    "data_imputaciones['SibSp_median'] = round(data_imputaciones['SibSp_median'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76bc17e3",
   "metadata": {},
   "source": [
    "Parch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "83d14b1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_imputaciones['Parch_mean'] = imp_mean.fit_transform(data[['Parch']])\n",
    "data_imputaciones['Parch_mean'] = round(data_imputaciones['Parch_mean'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "aa9054c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_imputaciones['Parch_mode'] = imp_mode.fit_transform(data[['Parch']])\n",
    "data_imputaciones['Parch_mode'] = round(data_imputaciones['Parch_mode'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "6a37bd2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_imputaciones['Parch_median'] = imp_median.fit_transform(data[['Parch']])\n",
    "data_imputaciones['Parch_median'] = round(data_imputaciones['Parch_median'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66df32ea",
   "metadata": {},
   "source": [
    "Fare"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "540ed2be",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_imputaciones['Fare_mean'] = imp_mean.fit_transform(data[['Fare']])\n",
    "data_imputaciones['Fare_mean'] = round(data_imputaciones['Fare_mean'], 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "5a206ac8",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_imputaciones['Fare_mode'] = imp_mode.fit_transform(data[['Fare']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "c4bbd9a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_imputaciones['Fare_median'] = imp_median.fit_transform(data[['Fare']])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a9e76e4",
   "metadata": {},
   "source": [
    "Embarked"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "8bd516d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_imputaciones['Embarked_mode'] = imp_mode.fit_transform(data[['Embarked']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "578024ac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sex_mode</th>\n",
       "      <th>Age_mean</th>\n",
       "      <th>Age_mode</th>\n",
       "      <th>Age_median</th>\n",
       "      <th>SibSp_mean</th>\n",
       "      <th>SibSp_mode</th>\n",
       "      <th>SibSp_median</th>\n",
       "      <th>Parch_mean</th>\n",
       "      <th>Parch_mode</th>\n",
       "      <th>Parch_median</th>\n",
       "      <th>Fare_mean</th>\n",
       "      <th>Fare_mode</th>\n",
       "      <th>Fare_median</th>\n",
       "      <th>Embarked_mode</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>male</td>\n",
       "      <td>38.00</td>\n",
       "      <td>38.0</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>71.28</td>\n",
       "      <td>71.28</td>\n",
       "      <td>71.28</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>female</td>\n",
       "      <td>35.00</td>\n",
       "      <td>35.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>53.10</td>\n",
       "      <td>53.10</td>\n",
       "      <td>53.10</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>male</td>\n",
       "      <td>54.00</td>\n",
       "      <td>54.0</td>\n",
       "      <td>54.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>51.86</td>\n",
       "      <td>51.86</td>\n",
       "      <td>51.86</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>female</td>\n",
       "      <td>35.69</td>\n",
       "      <td>24.0</td>\n",
       "      <td>35.5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>16.70</td>\n",
       "      <td>16.70</td>\n",
       "      <td>16.70</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>female</td>\n",
       "      <td>58.00</td>\n",
       "      <td>58.0</td>\n",
       "      <td>58.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>26.55</td>\n",
       "      <td>26.55</td>\n",
       "      <td>26.55</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>178</th>\n",
       "      <td>female</td>\n",
       "      <td>47.00</td>\n",
       "      <td>47.0</td>\n",
       "      <td>47.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>78.96</td>\n",
       "      <td>26.55</td>\n",
       "      <td>56.93</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>179</th>\n",
       "      <td>male</td>\n",
       "      <td>35.69</td>\n",
       "      <td>24.0</td>\n",
       "      <td>35.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.00</td>\n",
       "      <td>5.00</td>\n",
       "      <td>5.00</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>180</th>\n",
       "      <td>female</td>\n",
       "      <td>56.00</td>\n",
       "      <td>56.0</td>\n",
       "      <td>56.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>83.16</td>\n",
       "      <td>83.16</td>\n",
       "      <td>83.16</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>181</th>\n",
       "      <td>male</td>\n",
       "      <td>19.00</td>\n",
       "      <td>19.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>30.00</td>\n",
       "      <td>30.00</td>\n",
       "      <td>30.00</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>182</th>\n",
       "      <td>male</td>\n",
       "      <td>35.69</td>\n",
       "      <td>24.0</td>\n",
       "      <td>35.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>30.00</td>\n",
       "      <td>30.00</td>\n",
       "      <td>30.00</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>183 rows × 14 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    Sex_mode  Age_mean  Age_mode  Age_median  SibSp_mean  SibSp_mode  \\\n",
       "0       male     38.00      38.0        38.0         1.0         1.0   \n",
       "1     female     35.00      35.0        35.0         1.0         1.0   \n",
       "2       male     54.00      54.0        54.0         0.0         0.0   \n",
       "3     female     35.69      24.0        35.5         1.0         1.0   \n",
       "4     female     58.00      58.0        58.0         0.0         0.0   \n",
       "..       ...       ...       ...         ...         ...         ...   \n",
       "178   female     47.00      47.0        47.0         1.0         1.0   \n",
       "179     male     35.69      24.0        35.5         0.0         0.0   \n",
       "180   female     56.00      56.0        56.0         0.0         0.0   \n",
       "181     male     19.00      19.0        19.0         0.0         0.0   \n",
       "182     male     35.69      24.0        35.5         0.0         0.0   \n",
       "\n",
       "     SibSp_median  Parch_mean  Parch_mode  Parch_median  Fare_mean  Fare_mode  \\\n",
       "0             1.0         0.0         0.0           0.0      71.28      71.28   \n",
       "1             1.0         0.0         0.0           0.0      53.10      53.10   \n",
       "2             0.0         0.0         0.0           0.0      51.86      51.86   \n",
       "3             1.0         0.0         0.0           0.0      16.70      16.70   \n",
       "4             0.0         0.0         0.0           0.0      26.55      26.55   \n",
       "..            ...         ...         ...           ...        ...        ...   \n",
       "178           1.0         1.0         1.0           1.0      78.96      26.55   \n",
       "179           0.0         0.0         0.0           0.0       5.00       5.00   \n",
       "180           0.0         0.0         0.0           0.0      83.16      83.16   \n",
       "181           0.0         0.0         0.0           0.0      30.00      30.00   \n",
       "182           0.0         0.0         0.0           0.0      30.00      30.00   \n",
       "\n",
       "     Fare_median Embarked_mode  \n",
       "0          71.28             C  \n",
       "1          53.10             S  \n",
       "2          51.86             S  \n",
       "3          16.70             S  \n",
       "4          26.55             S  \n",
       "..           ...           ...  \n",
       "178        56.93             S  \n",
       "179         5.00             S  \n",
       "180        83.16             S  \n",
       "181        30.00             S  \n",
       "182        30.00             C  \n",
       "\n",
       "[183 rows x 14 columns]"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_imputaciones"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c82bdb56",
   "metadata": {},
   "source": [
    "Regresion lineal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "0a4e4457",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "643d42f9",
   "metadata": {},
   "source": [
    "Age"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6146e978",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_sin_nan = "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "29caa37d",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Input contains NaN, infinity or a value too large for dtype('float64').",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Input \u001b[0;32mIn [101]\u001b[0m, in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m lm \u001b[38;5;241m=\u001b[39m LinearRegression()\n\u001b[0;32m----> 2\u001b[0m lm \u001b[38;5;241m=\u001b[39m \u001b[43mlm\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m[\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mFare\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mSibSp\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mParch\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mAge\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      3\u001b[0m lm\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:662\u001b[0m, in \u001b[0;36mLinearRegression.fit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    658\u001b[0m n_jobs_ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_jobs\n\u001b[1;32m    660\u001b[0m accept_sparse \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpositive \u001b[38;5;28;01melse\u001b[39;00m [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcsr\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcsc\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcoo\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m--> 662\u001b[0m X, y \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_validate_data\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    663\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maccept_sparse\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maccept_sparse\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_numeric\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmulti_output\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\n\u001b[1;32m    664\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    666\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m sample_weight \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    667\u001b[0m     sample_weight \u001b[38;5;241m=\u001b[39m _check_sample_weight(sample_weight, X, dtype\u001b[38;5;241m=\u001b[39mX\u001b[38;5;241m.\u001b[39mdtype)\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/sklearn/base.py:581\u001b[0m, in \u001b[0;36mBaseEstimator._validate_data\u001b[0;34m(self, X, y, reset, validate_separately, **check_params)\u001b[0m\n\u001b[1;32m    579\u001b[0m         y \u001b[38;5;241m=\u001b[39m check_array(y, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mcheck_y_params)\n\u001b[1;32m    580\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 581\u001b[0m         X, y \u001b[38;5;241m=\u001b[39m \u001b[43mcheck_X_y\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mcheck_params\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    582\u001b[0m     out \u001b[38;5;241m=\u001b[39m X, y\n\u001b[1;32m    584\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m no_val_X \u001b[38;5;129;01mand\u001b[39;00m check_params\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mensure_2d\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mTrue\u001b[39;00m):\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/sklearn/utils/validation.py:964\u001b[0m, in \u001b[0;36mcheck_X_y\u001b[0;34m(X, y, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, multi_output, ensure_min_samples, ensure_min_features, y_numeric, estimator)\u001b[0m\n\u001b[1;32m    961\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m y \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    962\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124my cannot be None\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 964\u001b[0m X \u001b[38;5;241m=\u001b[39m \u001b[43mcheck_array\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    965\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    966\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccept_sparse\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maccept_sparse\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    967\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccept_large_sparse\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maccept_large_sparse\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    968\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    969\u001b[0m \u001b[43m    \u001b[49m\u001b[43morder\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43morder\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    970\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    971\u001b[0m \u001b[43m    \u001b[49m\u001b[43mforce_all_finite\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mforce_all_finite\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    972\u001b[0m \u001b[43m    \u001b[49m\u001b[43mensure_2d\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mensure_2d\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    973\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_nd\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mallow_nd\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    974\u001b[0m \u001b[43m    \u001b[49m\u001b[43mensure_min_samples\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mensure_min_samples\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    975\u001b[0m \u001b[43m    \u001b[49m\u001b[43mensure_min_features\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mensure_min_features\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    976\u001b[0m \u001b[43m    \u001b[49m\u001b[43mestimator\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    977\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    979\u001b[0m y \u001b[38;5;241m=\u001b[39m _check_y(y, multi_output\u001b[38;5;241m=\u001b[39mmulti_output, y_numeric\u001b[38;5;241m=\u001b[39my_numeric)\n\u001b[1;32m    981\u001b[0m check_consistent_length(X, y)\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/sklearn/utils/validation.py:800\u001b[0m, in \u001b[0;36mcheck_array\u001b[0;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator)\u001b[0m\n\u001b[1;32m    794\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    795\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFound array with dim \u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m. \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m expected <= 2.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    796\u001b[0m             \u001b[38;5;241m%\u001b[39m (array\u001b[38;5;241m.\u001b[39mndim, estimator_name)\n\u001b[1;32m    797\u001b[0m         )\n\u001b[1;32m    799\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m force_all_finite:\n\u001b[0;32m--> 800\u001b[0m         \u001b[43m_assert_all_finite\u001b[49m\u001b[43m(\u001b[49m\u001b[43marray\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mallow_nan\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mforce_all_finite\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m==\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mallow-nan\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    802\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m ensure_min_samples \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m    803\u001b[0m     n_samples \u001b[38;5;241m=\u001b[39m _num_samples(array)\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/sklearn/utils/validation.py:114\u001b[0m, in \u001b[0;36m_assert_all_finite\u001b[0;34m(X, allow_nan, msg_dtype)\u001b[0m\n\u001b[1;32m    107\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m    108\u001b[0m         allow_nan\n\u001b[1;32m    109\u001b[0m         \u001b[38;5;129;01mand\u001b[39;00m np\u001b[38;5;241m.\u001b[39misinf(X)\u001b[38;5;241m.\u001b[39many()\n\u001b[1;32m    110\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m allow_nan\n\u001b[1;32m    111\u001b[0m         \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m np\u001b[38;5;241m.\u001b[39misfinite(X)\u001b[38;5;241m.\u001b[39mall()\n\u001b[1;32m    112\u001b[0m     ):\n\u001b[1;32m    113\u001b[0m         type_err \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minfinity\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m allow_nan \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNaN, infinity\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m--> 114\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    115\u001b[0m             msg_err\u001b[38;5;241m.\u001b[39mformat(\n\u001b[1;32m    116\u001b[0m                 type_err, msg_dtype \u001b[38;5;28;01mif\u001b[39;00m msg_dtype \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m X\u001b[38;5;241m.\u001b[39mdtype\n\u001b[1;32m    117\u001b[0m             )\n\u001b[1;32m    118\u001b[0m         )\n\u001b[1;32m    119\u001b[0m \u001b[38;5;66;03m# for object dtype data, we only check for NaNs (GH-13254)\u001b[39;00m\n\u001b[1;32m    120\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m X\u001b[38;5;241m.\u001b[39mdtype \u001b[38;5;241m==\u001b[39m np\u001b[38;5;241m.\u001b[39mdtype(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mobject\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m allow_nan:\n",
      "\u001b[0;31mValueError\u001b[0m: Input contains NaN, infinity or a value too large for dtype('float64')."
     ]
    }
   ],
   "source": [
    "lm = LinearRegression()\n",
    "lm = lm.fit(data[['Fare', 'SibSp', 'Parch']], data['Age'])\n",
    "lm"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
